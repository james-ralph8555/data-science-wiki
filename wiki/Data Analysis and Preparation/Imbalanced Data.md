- Oversampling - simply duplicate samples from minority class.  Works well for Neural Networks
- Undersampling - drop data from majority class. Not ideal.
- SMOTE - Synthetic Minority Oversampling TEchnique - oversamples from minority class using [[K-Nearest-Neighbors|KNN]] and undersamples majority clas
- Probablity threshold can be changed to adjust tradeoff of false positives/false negatives - [[Confusion Matrix#ROC Curve]] shows the tradeoff